{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization bold text using Python Split function [split()]**"
      ],
      "metadata": {
        "id": "9s40FLueRaO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"My name is Vamsiteja. I'm from Andhra Pradesh and I'm  currently pursuing BE CSE AIML from Chandigarh University I want to become Machine Learning Engineer, and I'm focusing on my coding skills.\"\"\""
      ],
      "metadata": {
        "id": "nT6pJdOZRhQF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJv3PaoARPTp",
        "outputId": "71e08acc-49d9-4c9d-900d-825664122012"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Vamsiteja.',\n",
              " \"I'm\",\n",
              " 'from',\n",
              " 'Andhra',\n",
              " 'Pradesh',\n",
              " 'and',\n",
              " \"I'm\",\n",
              " 'currently',\n",
              " 'pursuing',\n",
              " 'BE',\n",
              " 'CSE',\n",
              " 'AIML',\n",
              " 'from',\n",
              " 'Chandigarh',\n",
              " 'University',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'become',\n",
              " 'Machine',\n",
              " 'Learning',\n",
              " 'Engineer,',\n",
              " 'and',\n",
              " \"I'm\",\n",
              " 'focusing',\n",
              " 'on',\n",
              " 'my',\n",
              " 'coding',\n",
              " 'skills.']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.split('. ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De32YqQNRSG3",
        "outputId": "a0d52b8f-6213-4097-90b1-098f957fbba1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My name is Vamsiteja',\n",
              " \"I'm from Andhra Pradesh and I'm  currently pursuing BE CSE AIML from Chandigarh University I want to become Machine Learning Engineer, and I'm focusing on my coding skills.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmW_RdBgR9De",
        "outputId": "ac181d46-66ce-40c2-9419-f4edf2f429c7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLXo-aBOT-AL",
        "outputId": "65763f58-5803-49ce-dbef-bdd8ce77438f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD TOKENIZATION **\n",
        "\n"
      ],
      "metadata": {
        "id": "c4nz6xbaeqyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"\"\"My name is Vamsiteja. I'm from Andhra Pradesh and I'm  currently pursuing BE CSE AIML from Chandigarh University I want to become Machine Learning Engineer, and I'm focusing on my coding skills.\"\"\"\n",
        "words = word_tokenize(text)\n",
        "print(\"Word Tokenization:\", words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BCIUhLETQeB",
        "outputId": "73bcea87-b488-4466-eeb4-5f540ebe4242"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization: ['My', 'name', 'is', 'Vamsiteja', '.', 'I', \"'m\", 'from', 'Andhra', 'Pradesh', 'and', 'I', \"'m\", 'currently', 'pursuing', 'BE', 'CSE', 'AIML', 'from', 'Chandigarh', 'University', 'I', 'want', 'to', 'become', 'Machine', 'Learning', 'Engineer', ',', 'and', 'I', \"'m\", 'focusing', 'on', 'my', 'coding', 'skills', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTENCES TOKENIZATION**\n"
      ],
      "metadata": {
        "id": "E-8NFUL6e22y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"NLTK is a powerful library for natural language processing. It provides easy-to-use interfaces for many tasks.\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"Sentence Tokenization:\", sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hrh0ralT8i6",
        "outputId": "29481e19-a834-4237-9c2a-58c80b3aff82"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization: ['NLTK is a powerful library for natural language processing.', 'It provides easy-to-use interfaces for many tasks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGEXP TOKENIZATION**"
      ],
      "metadata": {
        "id": "Xtcv650de8Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "text = \"Keep calm and code in Python. Regular expressions are powerful tools.\"\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)\n",
        "print(\"RegExp Tokenization:\", words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYHyuQLQUOgX",
        "outputId": "3399db80-24ee-4dd7-cf48-c8880c849b9d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegExp Tokenization: ['Keep', 'calm', 'and', 'code', 'in', 'Python', 'Regular', 'expressions', 'are', 'powerful', 'tools']\n"
          ]
        }
      ]
    }
  ]
}